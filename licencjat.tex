\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{polski}
\usepackage[hidelinks]{hyperref}
\usepackage{natbib} % potrzba do bibliografii
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
%\usepackage[acronym]{glossaries} COS NIE DZIALA WYWALA BLEDY

\author{Kamila Choja}
\title{Wybrane zastosowanie statystycznych metod porządkowania danych wielowymiarowych}


\newtheorem{theorem}{Twierdzenie}[section]
\newtheorem{definition}[theorem]{Definicja}

\newcommand{\setR}{\mathbb{R}}

\newcommand{\Lp}[2]{\operatorname{L}_{#1} \left( {#2} \right)}
\newcommand{\norm}[2][]{\left\| {#2} \right\|_{#1}}
\newcommand{\distance}[3][d]{\operatorname{#1}\left( {#2}; {#3}\right)}
\newcommand{\mediana}{\operatorname{med}}

\newcommand{\closure}[1]{\overline{#1}}
\begin{document}
\begin{titlepage}
\begin{center}
        \vspace*{1cm}
        {\large POLITECHNIKA ŁÓDZKA}\\
       \vspace*{1cm}
        {\large WYDZIAŁ FIZYKI TECHNICZNEJ, INFORMATYKI I MATEMATYKI STOSOWANEJ}\\
        \vspace*{2cm}
    \end{center}        
        
\text{Kierunek: Matematyka}\\
\vspace*{0.3cm}
\hspace*{0.3cm}
\text{Specjalność: Matematyczne Metody Analizy Danych Biznesowych}
  
\begin{center}
\rule{\textwidth}{0.5pt}

\vspace*{0.5cm}
   
{\large WYBRANE ZASTOSOWANIE STATYSTYCZNYCH METOD\\ }
{\large PORZĄDKOWANIA DANYCH WIELOWYMIAROWYCH\\}
\vspace*{1cm}


\begin{flushright}
Kamila Choja\\
Nr albumu: 204052 
 \end{flushright}
\rule{\textwidth}{0.5pt}

Praca licencjacka\\
napisana w Instytucie Matematyki Politechniki Łódzkiej\\

\vspace*{2cm}

Promotor: dr, mgr inż. Piotr Kowalski\\
\vfill
ŁÓDŹ, xxx 2017


     \end{center}   
\end{titlepage}

\tableofcontents

\chapter{Wstęp}


\chapter{Preliminaria}  

\section{Notacja}   
\begin{itemize}
\item $R^m$ - przestrzeń liniowa, wektorowa, jej elementy nazywamy zamiennie wektorami lub punktami
\item $\mathcal{E}^n$ - przestrzeń euklidesowa n-wymiarowa
\item O = $\{$O$_{1}$, O$_{2}$, ..., O$_{n}\}$ - zbiór obiektów przestrzennych
\item X = $\{$X$_{1}$, X$_{2}$, ..., X$_{m}\}$ - zbiór zmiennych (cech)
\item T = $\{$T$_{1}$, T$_{2}$, ..., T$_{k}\}$ - zbiór okresów (jednostek czasu)
\item OX = O $\cdot$ X - zbiór obiekto-zmiennych 
\item OT = O $\cdot$ T - zbiór obiekto-okresów
\item XT = X $\cdot$ T - zbiór zmienno-okresów
\item OXT = O $\cdot$ X $\cdot$ T - zbiór obiekto-zmienno-okresów
\item $\Omega$ - przestrzeń zdarzeń elementarnych
\item $\omega$ - zdarzenie elementarne 
\item $\mathcal{F}$ - rodzina podzbiorów zbioru $\Omega$
\item $\mediana (X_{j})$ - mediana cechy $X_{j}$
\item $\rho$ - relacja porządkująca
\item $G$ - graf prosty
\item $V(G)$ - zbiór wierzchołków grafu $G$
\item $E(G)$ - krawędzie grafu $G$
\item $D$ - graf skierowany(digraf)
\item $V(D)$ - zbiór wierzchołków digrafu $D$
\item $A(D)$ - rodzina łuków digrafu $D$


\end{itemize}
\newpage

\section{Słownik użytych pojęć}
W pracy zostały wykorzystane następujące pojęcia, których wytłumaczenie znajduje się poniżej. 
\begin{itemize}
\item Statystyka matematyczna \cite[Rozdział 1]{gren1}\\
Statystyka matematyczna zajmuje się metodami wnioskowania o całej zbiorowości statystycznej na podstawie zbadania pewnej jej części zwanej próbką lub próbą.\\
 
\item Cecha statystyczna \cite[Rozdział 1]{mlodak2006}\\
Cecha statystyczna jest to liczbowy opis przedmiotu dociekań tj. konkretnej dziedziny życia społeczno-gospodarczego.Służy ona do scharakteryzowania podmiotu badania.\\

\item Macierz obserwacji (\cite[Rozdział 2]{mlodak2006}\\
Niech $m>1$ oraz $n>1$ będą liczbami naturalnymi.  Macierzą obserwacji nazywamy macierz rozmiaru  $n \times m$  postaci
\begin{center}

$$X= \left[
        \begin{array}{ccccc}
x_{11} & x_{12} & ... & x_{1m}\\
x_{21} & x_{22} & ... & x_{2m}\\
$...$ & $...$ & $...$ & $...$\\
x_{n1} & x_{n2} & ... & x_{nm}
         \end{array}
     \right] $$
\end{center}
gdzie:
\\* $x_{ij}$ - zaobserwowana wartość $j$-tej cechy dla $i$-tego obiektu .\\

\item Skala porządkowa \cite[Rozdział 1.2]{panek2013}\\
Skalą porządkową nazywana jest skala, pozwalająca na stwierdzeniu identyczności lub różnic porównywanych obiektów, a także na porównywanie wariantów zmiennych zaobserwowanych w obiektach. Nie pozwala ona określić odległości między obiektami. Umożliwia zliczanie obiektów uporządkowanych(liczby relacji równości, nierówności, większości i mniejszości).\\

\item Skala przedziałowa \cite[Rozdział 1.2]{panek2013}\\
Skalą przedziałową nazywana jest skala, która w stosunku do skali porządkowej, pozwala obliczyć odległość między obiektami, dokonując pomiaru zmiennych za pomocą liczb rzeczywistych. Dla skali tej możliwe jest, obok operacji arytmetycznych dopuszczalnych dla skal o mniejszej mocy, także dodawanie i odejmowanie. Wartość zerowa na tej skali ma charakter umowny, co prowadzi do zachowania różnic między wartościami cechy, przy zmianie jednostek miary. \\

\item Skala ilorazowa \cite[Rozdział 1.2]{panek2013}\\
Skalą ilorazową nazywana jest skala, która jest podobna do skali przedziałowej(odwołanie), z tym że występuje w niej zero bezwględne(zero ogranicza lewostronnie zakres tej skali). Powoduje to, że można na tej skali obok operacji dopuszczalnych na skalach słabszych dokonywać także dzielenia i mnożenia, a tym samym przedstawiać dowolną wartość cechy danego obiektu jako wielokrotność wartości cechy dla innego obiektu.\\

\item Zmienna objaśniająca \cite[Rozdział 1.1] {grabinski1982}
Zmienną objaśniającą nazywamy zmienną w modelu statystycznym, która oddziałuje na zmienne objaśniane. Zmiennie  objaśniającą oznaczamy jako $X_{1}, ..., X_{k}$, z kolei zmienne objaśniane jako $Y$. \\

\item Stymulanta \cite[Rozdział 1.5]{panek2013}\\
Stymulantami nazywane są zmienne, których wysokie wartości badany w badanych obiektach są pożądane z punktu widzenia rozpatrywanego zjawiska.\\

\item Destymulanta \cite[Rozdział 1.5]{panek2013}\\
Destymulantami nazywane są zmienne, których wysokie wartości badany w badanych obiektach są niepożadane z punktu widzenia rozpatrywanego zjawiska.\\

\item Nominanta \cite[Rozdział 1.5]{panek2013}\\
Nominantami nazywane są zmienne, których odchylenia wartości w badanym obiekcie od wartości (lub przedziału wartości) uznawanych za najkorzystniejsze są niepożądane z punktu widzenia rozpatrywanego zjawiska.\\

\item Transformacja normalizacyjna \cite[Rozdział 1.5]{panek2013}\\
Transformacją zmiennych diagnostycznych, mających na celu ujednolicenie ich jednostek pomiarowych, przy zastosowaniu zmiennych diagnostycznych, nazywana jest transformacją normalizacyjną. Można ją przeprowadzić na zmiennych, opisujących porównywane obiekty, mierzonych na skali przedziałowej lub ilorazowej.\\ 
\\*Ogólny wzór na przekształcenie normalizacyjne(Borys, 1978; Grabiński i in., 1989):
\begin{center}
\begin{equation}
z_{ij}=\left(\frac{x_{ij} - a}{b}\right)^p , i=1,2,...,n; j=1,2,...,m; b\neq0,
\end{equation}\\
\end{center}
gdzie:
\\* $z_{ij}$ - znormalizowana wartość $j$-tej zmiennej w $i$-tym obiekcie,
\\* $a,b,p$ - parametry normalizacyjne.
\item Średnia arytmetyczna z próby \cite[Rozdział 2.2]{mlodak2006}\\
Średnią arytmetyczną wartości cechy $X_{j}$ nazywamy wartość 
\begin{center}
$$\overline{x_{j}}= \frac{\sum_{i=1}^{n} x_{ij}}{n}$$\\
\end{center}

\item Odchylenie standardowe z próby \cite[Rozdział 2.2]{mlodak2006}\\
Odchyleniem standardowym cechy $X_{j}$  nazywamy wartość 
\begin{center}

$$s_{j}= \sqrt{ s_{j}^2} = \sqrt{\frac{1}{n}\sum_{i=1}^{n} (x_{ij} - \overline{x_{j}})^2}$$\\

\end{center}

\item Mediana \cite[Rozdział 2.2]{mlodak2006}\\
Medianę cechy $X_{j}$ nazywamy wartość \\
\begin{center}

med$(X_{j})= 
y = \left\{ \begin{array}{ll}
\frac{1}{2}\big(x_{(\frac{n}{2})j} + x_{(\frac{n}{2}+1)j}\big) & \textrm{jeśli n jest parzyste} \\\\
x_{(\frac{n+1}{2})j} & \textrm{jeśli n jest nieparzyste}\\

\end{array} \right.
$\\
\end{center}

\item Przestrzeń euklidesowa n-wymiarowa $\mathcal{E}^n$ \citep[Rozdział 9]{kuratowski2004}\\
Przestrzeń euklidesowa n-wymiarowa, jest przestrzenią metryczną przy zwykłej definicji odległości punktu $x=(x_1,x_2,...,x_n)$ od punktu $y=(y_1,y_2,...,y_n)$, danej wzorem Pitagorasa
\begin{center}
$$|x - y| =\sqrt{\sum_{i=1}^{n} |x_i - y_i|^2}$$
\end{center}
gdzie, $x$ i $y$ są ciągami złożonymi z n liczb rzeczywistych.
\end{itemize}
\newpage

%% TODO wprowadzic podstawowe pojecia rachunku prawdopodobieństwa
%% TODO wprowadzić przedstrzenie obiektów, cech, czasów oraz macierz obserwacji ''topologia

%% TODO w kolejnej sekcji o porządkach matematycznych

\section{Podstawowe pojęcia rachunku prawdopodobieństwa oraz statystyki}
Na potrzeby pracy, zostały wykorzystane pojęcia rachunku prawdopodobieństwa oraz statystyki, konieczne to zrozumienia danych jako próby losowej. W tym celu niezbędne było wprowadzenie definicji prawdopodobieństwa, zmiennej losowej, a także pojęć powiązanych z tymi definicjami tj. ciała zbiorów, $\sigma$-ciała zbiorów, przestrzeni zdarzeń elementarnych, zdarzenia losowego. Poniższej zostały one wypisane.\\

\begin{definition}{Ciało zbiorów \cite[Rozdział 8.1]{rudnicki2006}\\}
Rodzinę $A$ podzbiorów zbioru $X$ nazywamy ciałem zbiorów, jeżeli spełnia ona następujące warunku: \\
\begin{enumerate}
\item $\emptyset \in A$,
\item jeżeli $A \in \mathcal{A}$, to $X \ A \in \mathcal{A}$,
\item jeżeli $A \in \mathcal{A}$, to $A \cup B \in \mathcal{A}$.\\
\end{enumerate}
\end{definition}

\begin{definition}{$\sigma$-algebra/ciało zbiorów/ zbiorów mierzalnych\cite[Rozdział 8.1]{rudnicki2006}\\}
Ciało zbiorów $\mathcal{A}$ nazywamy $\sigma$-ciałem zbiorów, jeżeli spełnia ona warunek
dla dowolnych zbiorów $A_{n} \in \mathcal{A}, n \in \mathbb{N}$, mamy
\begin{center}
$\bigcup\limits_{i=1}^{\infty} A_n \in \mathcal{A}$.
\end{center}
Elementy $\sigma$-ciała $\mathcal{A}$ nazywamy zbiorami mierzalnymi.\\
\end{definition}

\begin{definition}{Przestrzeń zdarzeń elementarnych \cite[w oparciu o rozdział 1.1]{krysicki1999}\\}
Zbiór wszyskich możliwych wyników doświadczenia losowego nazywamy przestrzenią zdarzeń elementarnych i oznaczamy przez $\Omega$. Elementy zbioru $\Omega$ nazywamy zdarzeniami elementarnymi i oznaczamy $\omega$.\\
\end{definition}

\begin{definition}{Zdarzenie losowe \cite[w oparciu o rozdział 1.1]{krysicki1999}\\}
Zdarzeniem losowym (zdarzeniem) nazywamy każdy zbiór $\textit{A} \in \mathcal{F}$, gdzie $\mathcal{F}$ jest rodziną podzbiorów $\Omega$ spełniającą następujące warunki:
\begin{enumerate}
\item $\Omega \in F$;
\item Jeśli $A \in \mathcal{F}$, to $\textit{A$'$} \in \textit{F}$, gdzie $\textit{A$'$} = \Omega \backslash A $ jest zdarzeniem przeciwnym do zdarzenia $\textit{A}$;
\item Jeśli $\textit{A}_{i} \in \textit{F}$, $i= 1, 2, ...$,to $\bigcup\limits_{i=1}^{\infty} A_{i} \in \mathcal{F} $
\end{enumerate}
Rodzinę $\mathcal{F}$ spełniającą warunki 1 - 3 nazywamy $\sigma$-ciałem podzbiorów zbioru $\Omega$\\
\end{definition}

\begin{definition}{Przestrzeń propabilistyczna \cite[w oparciu o rozdział 1.2]{krysicki1999}\\}
Przestrzenią propabilistyczną nazywamy uporządkowaną trójkę $(\Omega, \mathcal{F}, P)$, gdzie $\Omega$ jest zbiorem zdarzeń elementarnych, $\mathcal{F}$ jest $\sigma$-ciałem podzbiorów $\Omega$, zaś $P$ jest prawdopodobieństwem określonym na $F$.\\
\end{definition}

\begin{definition}{Przestrzeń mierzalna w n-wymiarowej przestrzeni euklidesowej \cite[Rozdział 1]{bartoszewicz1996}\\}
Niech $(\Omega, F, P)$ oznacza przestrzeń propabilistyczną. Przestrzenią mierzalną w n-wymiarowej przestrzeni euklidesowej $R^n$, nazywamy uporządkowaną dwójkę $(R^n, \textit{B}^n)$, gdzie $\textit{B}^n$ jest $\sigma$-ciałem podzbiorów borelowskich tej przestrzeni, $n \geq 1$. \\
\end{definition}


\begin{definition}{Prawdopodobieństwo \cite[w oparciu o rozdział 1.1]{krysicki1999}\\}
Prawdopodobieństwem nazywamy dowolną funkcję $P$ o wartościach rzeczywistych, określoną na $\sigma$-ciele zdarzeń $\mathcal{F} \subset 2^\Omega$, spełniającą warunki: \\
\begin{enumerate}
\item $\textit{P(A)} \geq 0$ dla każdego $\textit{A} \in \mathcal{F}$
\item $\textit{P}(\Omega) = 1$
\item Jeśli $\textit{A}_{i} \in \mathcal{F}$, $i= 1, 2, ...$ oraz $A_{i} \cap A_{j}$ dla $i \neq j$, to 
\end{enumerate}
\begin{center}
$P \Big(\bigcup\limits_{i=1}^{\infty} A_{i} \Big)=\sum_{i=1}^{\infty} P(A_{i}) $\\
\end{center}
\end{definition}

\begin{definition}{Zmienna losowa \cite[Rozdział 2.1]{krysicki1999}\\}
Niech $(\Omega, \mathcal{F}, P)$ będzie dowolną przestrzenią propabilistyczną. Dowolną funkcję $\textit{X} : \Omega \rightarrow \mathbb{R}$ nazywamy zmienną losową jednowymiarową, jeśli dla dowolnej liczby rzeczywistej $x$ zbiór zdarzeń elementarnych $\omega$, dla których spełniona jest nierówność $X(\omega)< x$ jest zdarzeniem, czyli 
\begin{center}
$\{\omega: X(\omega) < x \} \in \textit{F}$ dla każdego $x \in \mathbb{R}$\\
\end{center}
\end{definition}


\begin{definition}{Funkcja mierzalna \cite[w oparciu o rozdział 8.2]{rudnicki2006}\\}
Niech $X$ będzie niepustym zbiorem, $A$  $\sigma$-ciałem na $X$ i $\overline{\mathbb{R}} = \mathbb{R} \cup \{-\infty, \infty \}$. Funkcję $f: X \rightarrow \overline{\mathbb{R}}$ nazywamy mierzalną, jeżeli zbiór
\begin{center}
$\{ x \in X: f(x) > a \}$
\end{center}
jest mierzalny przy dowolnym $a \in \mathbb{R}$.\\
\end{definition}

\begin{definition}{Wektor losowy n-wymiarowy \cite[Rozdział 1]{bartoszewicz1996}\\}
Wektorem losowym n-wymiarowym nazywamy funkcję $X: \Omega \rightarrow \mathbb{R}^n$ mierzalną względem $\sigma$-ciała $\mathcal{F}$ ($\mathcal{F}$-mierzalną), tzn. taką, że $X^{-1}(B) \in \mathcal{F}$ dla każdego $B \in \mathcal{F}$.\\
\end{definition}

\begin{definition}{Wartość oczekiwana \cite[Rozdział 2.6]{krysicki1999}\\}
Niech $X$ będzie zmienną losową typu dyskretnego lub ciągłego. Wartością oczekiwaną zmiennej losowej $X$ nazywamy 
\begin{center}
$E(X)=\left\{ \begin{array}{ll}
\sum_{i=1}^{n} x_ip_i &\textrm{jeśli zmienna jest typu dyskretnego} \\\\
\int_{-\infty}^{\infty} xf(x)dx & \textrm{jeśli zmienna jest typu ciągłego}\\
\end{array} \right.$\\
\end{center}
\end{definition}

\begin{definition}{Wartość oczekiwana macierzy losowej $X$ \cite[Rozdział 1.3]{bartoszewicz1996}\\}
Wartością oczekiwaną macierzy losowej $X$ nazywamy macierz postaci
\begin{center}
$E(X)=\left[
        \begin{array}{ccccc}
E(X_{11}) & E(X_{12}) & ... & E(X_{1r})\\
E(X_{21}) & E(X_{22}) & ... & E(X_{2r})\\
$...$ & $...$ & $...$ & $...$\\
E(X_{n1}) & E(X_{n2}) & ... & E(X_{nr})
         \end{array}
     \right] $\
\end{center}
przy założeniu, że wszystkie wartości oczekiwane $E(X_{ij})$, $i=1, 2, ..., n, j=1, 2, ..., r$, istnieją.\\
\end{definition}

\begin{definition}{Macierz kowariancji n-wymiarowego wektora losowego $X$ \cite[Rozdział 1]{bartoszewicz1996}\\}
Macierzą kowariancji n-wymiarowego wektora losowego $X$ nazywamy macierz
\begin{center}
$\sum=E\{[X-E(X)][X-E(X)]'\}$\\
\end{center}
\end{definition}

\begin{definition}{Kowariancja \cite[Rozdział 1]{bartoszewicz1996}\\}
Niech $X_{i}$ i $X_{j}$ będą zmiennymi losowymi, $\sum$ będzie macierzą kowariancji n-wymiarowego wektora losowego $X$. Kowariancją zmiennych losowych $X_{i}$ i $X_{j}$, nazywamy 
\begin{center}
$cov(X_{i},X_{j})=\sigma_{ij}=E\{[X_{i}-E(X_{i})][X_{j}-E(X_{j})]\}$, $i, j= 1, 2, ..., n$
\end{center}
gdzie $\sigma_{ij}$ jest elementem macierzy kowariancji n-wymiarowego wektora losowego $X$.\\
\end{definition}

\begin{definition}{Współczynnik Pearsona \cite[Rozdział 2.2]{mlodak2006}\\}
Współczynnik Pearsona oznaczamy: 
\begin{center}
$r_{jk}= \frac{cov(X_{j},X_{k})}{s_{j}s_{k}}$\\

\end{center}
gdzie:
\\* $cov(X_{j},X_{k})$ - kowariancja cech $X_{j}$ i $X_{k}$ .\\
\end{definition}

\begin{definition} {Macierz korelacji par zmiennych \cite[Rozdział 2.2]{mlodak2006}\\}
Macierzą korelacji par zmiennych, nazywamy macierz postaci:
\begin{center}
$R= \left[
        \begin{array}{ccccc}
1 & r_{12} & ... & r_{1m}\\
r_{21} & 1 & ... & r_{2m}\\
$...$ & $...$ & $...$ & $...$\\
r_{m1} & r_{m2} & ... & 1
         \end{array}
     \right] $
\end{center}
gdzie:
\\* $r_{jk}$ - współczynnik korelacji liniowej Pearsona $j$-tej i $k$-tej cechy (czyli $X_{j}$ oraz $X_{k}$) .\\
\end{definition}

\newpage
\section{Podstawowe pojęcia teorii grafów}
W pracy zostaną opisane zarówno metody porządkowania liniowego jak i nieliniowego, w tym celu należy wprowadzić definicje związane z teorią grafów, niezbędne przy opisywaniu metod porządkowania nieliniowego.\newline
W celu wprowadzeniu definicji, należy wcześniej podać niezbędne pojęcia dotyczące grafów. Niezmiernie istotne jest podanie pojęć dotyczących grafów, dzięki którym później zostaną wprowadzone definicje.\newline
Poniższe pojęcia zostały opracowane na podstawie \cite{wilson2008}\\

%grafika grafu z wierzchołkami zastanowic sie  https://www.sharelatex.com/learn/Inserting_Images
%make glossary do wprowadzenia pojec -> poczytac i sie zastanowic




\begin{definition}{Graf prosty \cite[Rozdział 2]{wilson2008}\\}
Niech $G$ będzie grafem prostym, tj. grafem składającym się z niepustego zbioru skończonego $V(G)$, którego elementy nazywamy wierzchołkami (lub węzłami), i skończonego zbioru $E(G)$ różnych par nieuporządkowanych różnych elementów zbioru $V(G)$, które nazywamy krawędziami. Zbiór $V(G)$ nazywamy zbiorem wierzchołków, a zbiór $E(G)$ ($E(G) \subseteq \{\{u,v\}: u,v \in V, u\neq v\}$) zbiorem krawędzi grafu $G$.\\
Mówimy, że krawędź $\{v,w\}$ łączy wierzchołki $v$ i $w$, i na ogół oznaczamy ją krócej symbolem $vw$.\\
\end{definition}

\begin{definition}{Pętle \cite[Rozdział 2]{wilson2008}\\}
Pętlami nazywamy krawędzie wielokrotne, łączące wierzchołek z samym sobą.\\
\end{definition}

\begin{definition}{Graf/graf ogólny \cite[Rozdział 2]{wilson2008}\\}
Grafem nazywamy obiekt, w którym występują krawędzie wielokrotne oraz pętle.\\
\end{definition}

\begin{definition}{Trasa/marszruta \cite[Rozdział 3]{wilson2008}\\}
Trasą (lub marszrutą) w danym grafie $G$ nazywamy skończony ciąg krawędzi postaci $v_{0}v_{1}, v_{1}v_{2}, ..., v_{m-1}v_{m}$, zapisywany również w postaci $v_{0} \rightarrow{} v_{1} \rightarrow{} v_{2} \rightarrow{} ... \rightarrow{} v_{m}$, w którym każde dwie kolejne krawędzie są albo sąsiednie, albo identyczne. Taka trasa wyznacza ciąg wierzchołków $v_{0}, v_{1}, ..., v_{m}$. Wierzchołek $v_{0}$ nazywamy wierzchołkiem początkowym, a wierzchołek $v_{m}$ wierzchołkiem końcowym trasy; mówimy też wtedy, o trasie od wierzchołka $v_{0}$ do wierzchołka $v_{m}$. Liczbę  krawędzi na trasie nazywamy długością trasy. \\
\end{definition}

\begin{definition}{Ścieżka \cite[Rozdział 3]{wilson2008}\\}
Trasą, w której wszystkie krawędzie są różne, nazywamy ścieżką.\\
\end{definition}

\begin{definition}{Droga \cite[Rozdział 3]{wilson2008}\\}
Ścieżkę, w której wierzchołki $v_{0}, v_{1}, ..., v_{m}$ są różne (z wyjątkiem, być może, równości $v_{0}=v_{m}$), nazywamy drogą. \\
\end{definition}

\begin{definition}{Droga zamknięta/ścieżka zamknięta \cite[Rozdział 3]{wilson2008}\\}
Droga lub ścieżka jest zamknięta, jeśli $v_{0}=v_{m}$.\\
\end{definition}

\begin{definition}{Cykl \cite[Rozdział 3]{wilson2008}\\}
Ścieżką zamkniętą zawierającą co najmniej jedną krawędź nazywamy cyklem. \\
\end{definition}

\begin{definition}{Graf spójny \cite[Rozdział 3]{wilson2008}\\}
Graf jest spójny wtedy i tylko wtedy, gdy każda para wierzchołków jest połączona drogą.\\
\end{definition}
%%ilustracja grafu spójnego

\begin{definition}{Drzewo \cite[Rozdział 4]{wilson2008}\\}
Drzewem nazywamy graf spójny, nie zawierający cykli.\\
\end{definition}
%dodac grafike drzewa

\begin{definition}{Graf skierowany \cite[Rozdział 7]{wilson2008}\\}
Graf skierowany lub digraf $D$, skała się z niepustego zbioru skończonego $V(D)$ elementów nazywanych wierzchołkami i skończonej rodziny $A(D)$ par uporządkowanych elementów zbioru $V(D)$, nazywanych łukami. Zbiór $V(D)$ nazywamy zbiorem wierzchołków, a rodzinę $A(D)$ rodziną łuków digrafu D. Łuk $(v,w)$ zwykle zapisujemy jako $vw$.\\
\end{definition}

%dodac podstawowe pojecia zwiazane z diagramami, diagramem hessego
\newpage
\section{Relacja porządkująca}
W niniejszej pracy skupiamy się na zagadnieniu porządkowania danych wielowymiarowych. Koniecznym jest zatem przywołanie odpowiednich sformułowań dotyczących matematycznej definicji porządku. Najbardziej podstawowym pojęciem jest relacja porządku, którą teraz definiujemy\\

\begin{definition}{Relacja porządkująca \cite[Rozdział 1]{kuratowski2004}\\}
Niech dana relacja $\rho$, którą oznaczać będziemy przez $\leq$, będzie określona dla elementów ustalonego zbioru $X$. Mówimy, że relacja $\leq$ jest relacją porządkującą, jeśli spełnione są warunki:
\begin{enumerate}
\item $x \leq x$ dla każdego $x$ (zwrotność),
\item jeśli $x \leq y$ i $y \leq x$, to $x=y$,
\item jeśli $x \leq y$ i $y \leq z$, to $x \leq z$ (przechodniość).\\
\end{enumerate}
\end{definition}

\begin{definition}{Relacja liniowo porządkująca (liniowy porządek) \cite[Rozdział 2]{blaszczyk2007}\\}
Niech dany będzie zbiór $X$. Relację $\leq$ porządkującą zbiór $X$, nazywamy relacją liniowo porządkującą lub porządkiem liniowym, gdy dla dowolnych $x$, $y \in X$ spełnia ona następujący warunek liniowości:
\begin{center}
$x \leq y$ lub $y \leq x$
\end{center}
Parę $(X, \leq)$ nazywamy zbiorem liniowo uporządkowanym lub łańcuchem.\\
\end{definition}

\begin{definition}{Dobry porządek \cite[Rozdział 2]{blaszczyk2007}\\}
Niech dany będzie zbiór $X$. Relację $\leq$ porządkującą zbiór $X$, nazywamy dobrym porządkiem na zbiorze $X$, gdy w każdym niepustym podzbiorze zbioru $X$ istnieje element najmniejszy względem relacji $\leq$. Jeśli relacja $\leq$ na zbiorze $X$ jest dobrym porządkiem, to mówimy, że para $(X,\leq)$ jest zbiorem dobrze uporządkowanym.\\
\end{definition}

\begin{definition}{Ograniczenie górne \cite[Rozdział 2]{blaszczyk2007}\\}
Niech $A \subseteq X$, gdzie $(X, \leq)$ jest zbiorem uporządkowanym. Element $x \in X$ nazywamy ograniczeniem górnym zbioru $A$ względem relacji $\leq$, gdy $a \leq x$ dla każdego $a \in A$. \\
\end{definition}

\begin{definition}{Ograniczenie dolne \cite[Rozdział 2]{blaszczyk2007}\\}
Niech $A \subseteq X$, gdzie $(X, \leq)$ jest zbiorem uporządkowanym. Element $y \in X$ nazywamy ograniczeniem dolnym zbioru $A$ względem relacji $\leq$, gdy $a \leq x$ dla każdego $a \in A$. \\
\end{definition}

\begin{definition}{Zbiór ograniczony z góry, zbiór ograniczony z dołu, zbiór ograniczony \cite[Rozdział 2]{blaszczyk2007}\\}
Niech $A \subseteq X$, gdzie $(X, \leq)$ jest zbiorem uporządkowanym. Zbiór nazywamy ograniczonym z góry (ograniczonym z dołu), jeśli ma on ograniczenie górne (dolne). 
$\newline$ 
Zbiór ograniczony z dołu i z góry nazywamy ograniczonym. \\
\end{definition}

\begin{definition}{Kres górny \cite[Rozdział 2]{blaszczyk2007}\\}
Niech $A \subseteq X$, gdzie $(X, \leq)$ jest zbiorem uporządkowanym. Jeśli zbiór $A$ jest ograniczony z góry i wśród ograniczeń górnych zbioru $A$ istnienie element najmniejszy $x_0$, to element ten nazywamy kresem górnym zbioru $A$ i oznaczamy symbolem $sup A$. Tak więc $x_0 =sup A$, gdy spełnione są następujące warunki:
\begin{enumerate}
\item $a \leq x_0$ dla każdego $a \in A$,
\item jeśli $a \leq x$ dla każdego $a \in A$, to $x_0 \leq x$.
\end{enumerate}
\end{definition}

\begin{definition}{Kres dolnym \cite[Rozdział 2]{blaszczyk2007}\\}
Niech $A \subseteq X$, gdzie $(X, \leq)$ jest zbiorem uporządkowanym. Jeśli zbiór $A$ jest ograniczony z dołu i wśród ograniczeń dolnych zbioru $A$ istnienie element największy $x_0$, to element ten nazywamy kresem dolnym zbioru $A$ i oznaczamy symbolem $inf A$. Tak więc $x_0 =inf A$, gdy spełnione są następujące warunki:
\begin{enumerate}
\item $y_0 \leq a$ dla każdego $a \in A$,
\item jeśli $y \leq a$ dla każdego $a \in A$, to $y \leq y_0$.
\end{enumerate}
\end{definition}

$\newline$
Przechodząc do dalszej dalszych pojęć związanych z porządkowaniem, przytoczę opis obiektu wzorcowego, a następnie podam jego formalną definicję.\\
$\newline$
Stwierdzenie w oparciu o \cite[Rozdział 2.2]{panek2013}\\
Obiektem wzorcowym nazywany jest obiekt modelowy o pożądanych wartościach zmiennych wejściowych.\\

\begin{definition}{Obiekt wzorcowy \cite[Rozdział 2.1]{mlodak2006}\\}
Obiektem wzorcowym, nazywamy obiekt powstały na podstawie macierzy wystandaryzowanych zmiennych wejściowych. Współrzędnymi obiektu są: \\
\begin{center}

$O_{0}=[z_{oj}], j= 1,2,...,m.$\\

\end{center}
gdzie:
\\*Współrzędne obiektu wzorcowego obliczamy na podstawie następującego wzoru: 
\begin{center}
$z_{oj}=max_{i}$
\end{center}
\begin{equation}
z_{oj}=\left\{ \begin{array}{ll}
\max\limits_{i} \Big\{z_{ij}\Big\}  & \textrm{dla  } z_{j}^S\\\\
\min\limits_{i}\Big\{ z_{ij} \Big\} & \textrm{dla } z_{j}^D\\
\end{array} \right.
\end{equation}
gdzie:
\\*$j=1,2,...,m; i=1,2,...,n.$\\
\end{definition}

\begin{definition}{Funkcja kryterium dobroci uporządkowania \cite[Rozdział 2.2]{panek2013}\\}
Funkcją kryterium dobroci uporządkowania nazywamy funkcję: 
\begin{center}
$$F^2= \sum_{i'=1}^{n-1} i' \sum_{i=1}^{n-i'} d_{ii'}$$\\

\end{center}
gdzie:
\\* $d_{i,i'}$ - odległość euklidesowa między $i$-tym i $i'$-tym obiektem . \\
\end{definition}

\chapter{Metody porządkowania}

Rozdział opracowany w oparciu o \cite[Rozdział 2]{panek2013}, metody porządkowania zbioru obiektów można podzielić na metody porządkowania liniowego i metody porządkowania nieliniowego. Obie grupy metod mogą stanowić punkt wyjścia do grupowania obiektów. \\
Metody porządkowania liniowego pozwalają na ustalenie hierarchii obiektów ze względu na określone kryterium. Problematyka związana z grupowaniem obiektów ma tutaj znaczenie drugoplanowe. Natomiast stosowanie metod porządkowania nieliniowego nie pozwala na ustalenie hierarchii obiektów, lecz wyłącznie wskazanie dla każdego z tych obiektów podobnych ze względu na wartości opisujących je zmiennych. Powoduje to, że porządkowanie nieliniowe stanowi przede wszystkim etap wstępny do grupowania obiektów.\\

\section{Metody porządkowania liniowego}

Porządkowanie liniowe obiektów polega, w ujęciu geometrycznym, na rzutowaniu na prostą punktów reprezentujących obiekty, umieszczonych w wielowymiarowej przestrzeni zmiennych. Takie postępowanie pozwala na ustalenie hierarchii obiektów, czyli uporządkowanie ich od obiektu stojącego najwyżej w tej hierarchii do obiektu znajdującego się najniżej. Poniżej zostaną przedstawione własności uporządkowania liniowego obiektów.\\

\begin{itemize}
\item każdy obiekt ma przynajmniej jednego sąsiada i nie więcej niż dwóch sąsiadów,
\item jeżeli sąsiadem $i$-tego obiektu jest $i'$-ty obiekt, to jednocześnie sąsiadem $i'$-tego obiektu jest $i$-ty obiekt,
\item dokładnie dwa obiekty mają tylko jednego sąsiada.\\
\end{itemize}
\noindent

Aby uporządkować liniowo obiekty, charakteryzujące je zmienne muszą być mierzone przynajmniej na skali porządkowej. Gdy zmienne te mierzone są na skali przedziałowej lub ilorazowej, należy dokonać ich normalizacji, dla zapewnienia ich porównywalności.

Metody porządkowania liniowego można podzielić na metody diagramowe, procedury oparte na zmiennej syntetycznej oraz procedury iteracyjne bazujące na optymalizacji funkcji kryterium dobroci uporządkowania.

\newpage
\subsection{Metody diagramowe}
\noindent

W metodach diagramowych stosuje się graficzną prezentację macierzy odległości zwanej diagramem. Przykładem metod diagramowych stanowi metoda Czekanowskiego. Punktem wyjścia tej metody, jest skonstruowanie macierzy odległości między obiektami $D=[d_{ii}]$, zdefiniowanej za pomocą dowolnej metryki. Mierniki odległości w macierzy odległości D dzieli się na klasy podobieństwa obiektów. Poszczególnym klasom podobieństwa obiektów przyporządkowuje się odpowiednie symbole graficzne, otrzymując nieuporządkowany diagram Czekanowskiego, co pozwala na wzrokową ocenę przebiegu porządkowania obiektów. Stąd też porządkowanie obiektów odbywa się poprzez porządkowanie diagramu. Polega ono na przestawieniu wierszy i odpowiadających im kolumn diagramu, tak aby symbole graficzne reprezentujące możliwie najmniejsze odległości skupiały się wzdłuż głównej przekątnej, a w miarę oddalania się od głównej przekątnej, pojawiały się symbole graficzne odpowiadające coraz większym odległościom. Kolejność uporządkowania obiektów jest określona przez kolejność odpowiadających im wierszy(kolumn).

Do optymalizacji porządkowania zaproponowane zostało pewne kryterium









%\begin{thebibliography}{99}
%\bibitem{gren1}
% J.Greń
%\emph{STATYSTYKA MATEMATYCZNA MODELE I ZADANIA},
%Państwowe Wydawnictwo Naukowe,wstęp, 18, Warszawa 1984
%\bibitem{panek1}
% T.Panek, J.K.Zwierzchowski.
%\emph{Statystyczne metody wielowymiarowej analizy porównawczej},
%SZKOŁA GŁÓWNA HANDLOWA W WARSZAWIE,rozdział 1.2, 18, Warszawa 2016
%\bibitem{panek2}
% T.Panek, J.K.Zwierzchowski.
%\emph{Statystyczne metody wielowymiarowej analizy porównawczej},
%SZKOŁA GŁÓWNA HANDLOWA W WARSZAWIE,rozdział 1.5.1, 33, Warszawa 2016
%\bibitem{panek3}
% T.Panek, J.K.Zwierzchowski.
%\emph{Statystyczne metody wielowymiarowej analizy porównawczej},
%SZKOŁA GŁÓWNA HANDLOWA W WARSZAWIE,rozdział 1.5.2, 35, Warszawa 2016
%\bibitem{panek4}
% T.Panek, J.K.Zwierzchowski.
%\emph{Statystyczne metody wielowymiarowej analizy porównawczej},
%SZKOŁA GŁÓWNA HANDLOWA W WARSZAWIE,rozdział 2.2., 58, Warszawa 2016
%\bibitem{panek5}
% T.Panek, J.K.Zwierzchowski.
%\emph{Statystyczne metody wielowymiarowej analizy porównawczej},
%SZKOŁA GŁÓWNA HANDLOWA W WARSZAWIE,rozdział 2.2.3, 77, Warszawa 2016
%\bibitem{grabinski1}
% T.Grabiński, S.Wydymus, A.Zelias.
%\emph{Metody doboru zmiennych w modelach ekonometrycznych},
%Państwowe Wydawnictwo Naukowe,rozdział 1,13, Warszawa 1982
%\bibitem{mlodak1}
%Andrzej Młodak
%\emph{Analiza Taksonomiczna W Statystyce Regionalnej},
%Centrum Doradztwa i Informacji Difin,rozdział 1.2,21, Warszawa 2006
%\bibitem{mlodak2}
%Andrzej Młodak
%\emph{Analiza Taksonomiczna W Statystyce Regionalnej},
%Centrum Doradztwa i Informacji Difin,rozdział 1.2,22, Warszawa 2006
%\bibitem{mlodak3}
%Andrzej Młodak
%\emph{Analiza Taksonomiczna W Statystyce Regionalnej},
%Centrum Doradztwa i Informacji Difin,rozdział 2.1,26, Warszawa 2006
%\bibitem{mlodak4}
%Andrzej Młodak
%\emph{Analiza Taksonomiczna W Statystyce Regionalnej},
%Centrum Doradztwa i Informacji Difin,rozdział 2.2,28, Warszawa 2006
%\bibitem{mlodak5}
%Andrzej Młodak
%\emph{Analiza Taksonomiczna W Statystyce Regionalnej},
%Centrum Doradztwa i Informacji Difin,rozdział 2.2,29, Warszawa 2006
%\bibitem{mlodak6}
%Andrzej Młodak
%\emph{Analiza Taksonomiczna W Statystyce Regionalnej},
%Centrum Doradztwa i Informacji Difin,rozdział 2.2,30, Warszawa 2006
%\end{thebibliography}
\bibliographystyle{plain}
\bibliography{plik_z_bibliografia}





%% F1 F11 F1 F1




\end{document}
